---
title: "Mathematics for Economics: Semester 1"
author: "Rob Smith"
date: "Updated `r format(Sys.time(), '%B %d, %Y')`"
output:
  beamer_presentation:
    theme: "Berkeley"
    colortheme: "seahorse"
    fonttheme: "serif"
    slide_level: 3
  bookdown::gitbook:
    config:
      toc:
        collapse: section
    self.contained: yes
    split_by: none
urlcolor: red
header-includes: 
  - \usepackage{tikz}
  - \usepackage{pgfplots}
  - \usepackage{fontawesome5}
  - \usepackage{academicons}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include=FALSE)
```

# Linear Algebra: Vectors and Matrices

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New section %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New section %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

## Multiplication
### Conditions for valid multiplication
- When we multiply two matrices, we get the dimensions of the new matrix from the rows of the first matrix and the columns of the second.
- If, recall the order of a matrix is $m\times n$:
- $\mathbf{A}$ is of order $(2 \times 3)$, $(3 \times 4)$ are $\mathbf{B}$'s dimensions
- We know that we can multiply them because $n_A = m_B = 3$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Conditions for valid multiplication
- To work out the dimensions of the NEW matrix, after we multiply, we take the number of rows from $\mathbf{A} = m_A = 2$, and the columns from $\mathbf{B}= n_B=4$
- In matrix terms:
$$
\begin{bmatrix}
     & \mathbf{A} & \\
    (m_A & \times & n_A)
\end{bmatrix}
\cdot
\begin{bmatrix}
     & \mathbf{B} & \\
    (m_B & \times & n_B)
\end{bmatrix}
=
\begin{bmatrix}
     & \mathbf{AB} & \\
    (n_A & \times & m_B)
\end{bmatrix}
$$

#### For example
$$
\begin{bmatrix}
     & \mathbf{A} & \\
    (2 & \times & \color{green}{7})
\end{bmatrix}
\cdot
\begin{bmatrix}
     & \mathbf{B} & \\
    (\color{green}{7} & \times & 3)
\end{bmatrix}
=
\begin{bmatrix}
     & \mathbf{AB} & \\
    (2 & \times & 3)
\end{bmatrix}
$$


<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Vectors follow the same rules

#### For example
$$
\begin{bmatrix}
     & \mathbf{A} & \\
    (1 & \times & \color{green}{4})
\end{bmatrix}
\cdot
\begin{bmatrix}
     & \mathbf{B} & \\
    (\color{green}{4} & \times & 1)
\end{bmatrix}
=
\begin{bmatrix}
     & \mathbf{AB} & \\
    (1 & \times & 1)
\end{bmatrix}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### When is it defined?

- [A first look at Matrix multiplication](https://www.youtube.com/watch?v=kT4Mp9EdVqs&index=6&list=PLGR_7q6BJHQFbTCW995GhRY1AwWuWOvBH)
- Matrix $\mathbf{A}=m_a\times n_a$, and matrix $\mathbf{B}=m_b\times n_b$, **can only be multiplied if** the number of columns in $\mathbf{A}$ equal the number of rows in $\mathbf{B}$.
- I.e. $\mathbf{AB}$ is only defined if: $n_a = m_b$
- And,  $\mathbf{BA}$ is only defined if: $n_b = m_a$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Vector multiplication

#### Special case of matrix multiplication
- It is useful to start with **vector** multiplication.
- If we have a row vector, the dimensions are $1 \times n$.
- If we have a column vector, they are $m \times 1$.

#### Order matters

- $\mathbf{a}(2 \times \color{green}{1}$$) \cdot \mathbf{b}(\color{green}{1}$ $\times 5)$ is good.
- $\mathbf{a}(1 \times \color{green}{6}$$) \cdot \mathbf{b}(\color{green}{6}$ $\times 1)$ is good.
- $\mathbf{a}(5 \times \color{green}{1}$$) \cdot \mathbf{b}(\color{green}{1}$ $\times 2)$ is good.
- $\mathbf{a}(2 \times \color{red}{1}$$) \cdot \mathbf{b}(\color{red}{3}$ $\times 1)$ is Impossible.
- $\mathbf{a}(1 \times \color{red}{7}$$) \cdot \mathbf{b}(\color{red}{1}$ $\times 6)$ is Impossible.

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### The dot product
- You will maybe have noticed that all of the products so far have been written with a dot ($\cdot$).
- When we multiply vectors and matrices, there are two possibilities:
    a. The dot ($\cdot$) product. (This is what we are going to focus on.)
    b. [The cross ($\times$) product](https://www.youtube.com/watch?v=pJzmiywagfY). (A measure of orthogonality, not in this course.)

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Some rules of thumb

#### Generically this can be written as
Suppose that $\mathbf{A} = (a_{ij})_{m \times n}$ and that $\mathbf{B} = (b_{ij})_{n \times p}$. The product of $\mathbf{A} \cdot \mathbf{B}$, is $\mathbf{C} = (c_{ij})_{m \times p}$, where the *i*th row and the *j*th column scalar product:

$$
c_{ij} = a_{i1}b_{1j} + a_{i2}b_{2j} + \dots + a_{in}b_{nj}
$$

- This is much easier to understand by practicing than it is by reading abstract equations!

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### A visual aid to the DOT product
```{r, out.width = "200px", include=TRUE, align="center"}
knitr::include_graphics("./images/multiplication.png")
```


<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### A simple example

$$
\mathbf{A}
  \begin{bmatrix}
    \color{red}{6} & \color{blue}{8} & \color{orange}{7} \\
    3 & 4 & 5
  \end{bmatrix}
\cdot \mathbf{B}
  \begin{bmatrix}
    \color{red}{9}      & 1\\
    \color{blue}{4}     & 10\\
    \color{orange}{11}  & 20
  \end{bmatrix}
=
$$
$$
  \begin{bmatrix}
    (6\cdot9)+(8\cdot4)+(7\cdot11)               &               (6\cdot1)+(8\cdot10)+(7\cdot20) \\
    (3\cdot9)+(4\cdot4)+(5\cdot11)               &               (3\cdot1)+(4\cdot10)+(5\cdot20) \\
  \end{bmatrix}
$$
$$
  \begin{bmatrix}
    (54)+(32)+(77)               &               (6)+(80)+(140) \\
    (18)+(16)+(55)               &               (3)+(40)+(100) \\
  \end{bmatrix}
$$
$$
  \mathbf{AB}=
  \begin{bmatrix}
    163     &  226 \\
    89      &  143 \\
  \end{bmatrix}
$$

### Some rules of thumb

#### If the DOT product is defined, then:
- It is ALWAYS $rows \times columns$.
- There is always a *row* in $\mathbf{A}$ that corresponds to the *column* in $\mathbf{B}$ you are looking at.
- **Start with the dimensions of the solution**, then use the location in the solution matrix to check which column and row you should be working from in the other two matrices.


<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->



### Matrix multiplication rules
- **ORDER MATTERS**
$$
\mathbf{A} \cdot \mathbf{B} \neq \mathbf{B} \cdot \mathbf{A}
$$
, or simply, 
$$
\mathbf{A}\mathbf{B} \neq \mathbf{B}\mathbf{A}
$$
- [Multiplying a matrix by a vector](https://www.youtube.com/watch?v=Awcj447pYuk&list=PLGR_7q6BJHQFbTCW995GhRY1AwWuWOvBH&index=8) ($2\times 3 \cdot 3\times 1$), $\mathbf{Aw}$.
- [Multiplying a matrix by a matrix](https://www.youtube.com/watch?v=OMA2Mwo0aZg&index=7&list=PLGR_7q6BJHQFbTCW995GhRY1AwWuWOvBH) ($2\times 3 \cdot 3\times 2$), $\mathbf{AB}$
- [Defined vs. undefined multiplication, some examples](https://www.youtube.com/watch?v=O1-9f1g0OsI&index=9&list=PLGR_7q6BJHQFbTCW995GhRY1AwWuWOvBH).

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Rules for vector products and scalar products

#### Rules:

If $\mathbf{a}$, $\mathbf{b}$ and $\mathbf{c}$ are arbitrary *n*-vectors and $\alpha$, $\beta$ are arbitrary numbers, then:

a. $\mathbf{a} \cdot \mathbf{b} = \mathbf{b} \cdot \mathbf{a}$
b. $\mathbf{a} \cdot (\mathbf{b} + \mathbf{c})  = \mathbf{a}\cdot \mathbf{b} + \mathbf{a}\cdot\mathbf{c}$
c. $(\alpha\mathbf{a})\cdot \mathbf{b} = \mathbf{a} \cdot (\alpha\mathbf{b}) = \alpha (\mathbf{a}\cdot\mathbf{b})$
d. $\mathbf{a}\cdot\mathbf{a} > 0 \Longleftrightarrow \mathbf{a}\neq \mathbf{0}$


<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Exercises
1. If possible, find $\mathbf{A} \cdot \mathbf{B}$?, for
$$
\mathbf{A}=
  \begin{bmatrix}
    1 & 2 & 3 \\
    3 & 4 & 5
  \end{bmatrix}
  , and, \mathbf{B}=
  \begin{bmatrix}
    1 & 2 & 3 \\
    1 & 2 & 3 \\
    3 & 4 & 5
  \end{bmatrix}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Exercises continued ...
2. If possible, find $\mathbf{A} \cdot \mathbf{B}$?, for
$$
\mathbf{A}=
  \begin{bmatrix}
    5 & 2\\
    3 & 4\\
    8 & 6
  \end{bmatrix}
  , and, \mathbf{B}=
  \begin{bmatrix}
    \frac{3}{5} & 2\\
    3 & 4\\
    5 & \frac{1}{2}
  \end{bmatrix}
$$
3. If possible, find $\mathbf{B} \cdot \mathbf{A}$?, for
$$
\mathbf{A}=
  \begin{bmatrix}
    5 & 2\\
    3 & 4\\
    c & 4
  \end{bmatrix}
  , and \quad \mathbf{B} =
  \begin{bmatrix}
    \frac{3}{5} & 2 & e34 & 900\\
    3 & 4 & g & 23\\
    5 & \frac{1}{2} & i43 & 12
  \end{bmatrix}
$$
4. For (3) above if possible find $\mathbf{B}^{T}\mathbf{A}?$


<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Matrix multiplication: Associative rule
- [Matrix multiplication IS associative](https://www.youtube.com/watch?v=8Ryfe82DTcM&index=11&list=PLGR_7q6BJHQFbTCW995GhRY1AwWuWOvBH)
- This means that as long as the order stays the same, the **sequence does NOT matter**! So, 
$$
(\mathbf{A}\mathbf{B})\mathbf{C} = \mathbf{A}(\mathbf{B}\mathbf{C})
$$


<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Matrix multiplication: NOT commutative rule
- [Matrix multiplication is NOT commutative!](https://www.youtube.com/watch?v=z-SU7P-gIoQ&index=10&list=PLGR_7q6BJHQFbTCW995GhRY1AwWuWOvBH)
- That means that **ORDER MATTERS**.
- As before, 
$$
\mathbf{A}\mathbf{B} \neq \mathbf{B}\mathbf{A}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Rules of Matrix Multiplication

If $\mathbf{A} = (a_{ij})_{m\times n}$ and $\mathbf{B} = (b_{ij})_{m\times n}$ and $\mathbf{C} = (c_{ij})_{m\times n}$ are $m\times n$ matrices, and $\delta$, $\alpha$ and $\beta$ are scalars (real numbers).

#### Then:
- $\mathbf{A} + \mathbf{B} = (a_{ij}+b_{ij})_{m\times n}$
- $\delta \mathbf{A} = (\delta a_{ij})_{m\times n}$
- $\mathbf{A} + \mathbf{B} = \mathbf{B} + \mathbf{A}$
- $(\mathbf{A} + \mathbf{B}) + \mathbf{C} = \mathbf{A} + (\mathbf{B} + \mathbf{C})$
- $(\alpha + \beta)\mathbf{A} = \alpha\mathbf{A} + \beta\mathbf{A}$
- $\alpha(\mathbf{A} + \mathbf{B}) = \alpha\mathbf{A} + \alpha\mathbf{B}$
- $\mathbf{A}\mathbf{B} \neq \mathbf{B}\mathbf{A}$, in most cases.
- $(\mathbf{A}\mathbf{B})\mathbf{C} = \mathbf{A}(\mathbf{B}\mathbf{C})$
- $(\mathbf{A} + \mathbf{B})\mathbf{C} = \mathbf{A}\mathbf{C} + \mathbf{B}\mathbf{C})$


<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### The link to linear systems of equations

#### Consider the following matrix-vector product

$$
\begin{bmatrix}
    2    &  3    &   2\\
    4    &  1    &   3\\
    0    &  1    &   7
\end{bmatrix}
\cdot
\begin{bmatrix}
    x_1 \\
    x_2 \\
    x_3
\end{bmatrix}
=
$$
$$
\begin{bmatrix}
    2\cdot x_1 & +   &  3\cdot x_2  & +  &   2\cdot x_2\\
    4\cdot x_1 & +   &  1\cdot x_2  & +  &   3\cdot x_2\\
    0\cdot x_1 & +   &  1\cdot x_2  & +  &   7\cdot x_2
\end{bmatrix}=
$$
$$
\begin{matrix}
    2x_1    & +   &  3x_2   & +  &   2x_3\\
    4x_1    & +   &  x_2    & +  &   3x_3\\
            &     &  x_2    & +  &   7x_3
\end{matrix}
$$
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New section %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New section %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

## The identity matrix
### Some simple algebraic comparisons
- In regular algebra, for any real number, $a\times 1 = 1$
- In matrices there is a similar concept, called
[The Identity Matrix](https://www.youtube.com/watch?time_continue=297&v=iUQR0enP7RQ) , denoted by $\mathbf{I}$.
- Like the number 1 in normal algebra, in matrices, $\mathbf{I} \cdot\mathbf{A} = \mathbf{A}$
- Also, $\mathbf{A} \cdot \mathbf{I} = \mathbf{A}$, but will the dimensions of $\mathbf{I}$ be the same?

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### An illustration
- To illustrate the concept, we will find the identity matrix for:
$$
\mathbf{A}=
\begin{bmatrix}
    5 & 2 & 9\\
    3 & 4 & 1\\
    c & 4 & 7
\end{bmatrix}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### How should it look and how does it work?
- Using matrix multiplication rules, rows by columns:
$$
\mathbf{I}
    \begin{bmatrix}
        ? & ? & ?\\
        ? & ? & ?\\
        ? & ? & ?
    \end{bmatrix}
    \cdot \mathbf{A}
    \begin{bmatrix}
        5 & 2 & 9\\
        3 & 4 & 1\\
        c & 4 & 7
    \end{bmatrix}
    = \mathbf{IA}=
    \begin{bmatrix}
        5 & 2 & 9\\
        3 & 4 & 1\\
        c & 4 & 7
    \end{bmatrix}
$$
- What would that *Identity Matrix* need to look like?
- Think back to **vector multiplication**...

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### It is actually quite simple
- $\mathbf{I}$ for any matrix can therefore be found VERY easily.
- We only need to know the order of the matrix for which we want the identity matrix.
- Think about how the dot(.)product works in matrix multiplication.
- Each column by each row, to get each element of the final product.
- We want all values except 1 in each row/column to be zero. We just need the value to be in the right place!

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### What does this look like?
$$
\mathbf{I}_2 =
    \begin{bmatrix}
        1 & 0\\
        0 & 1
    \end{bmatrix}
    , \quad \mathbf{I}_3 =
    \begin{bmatrix}
        1 & 0 & 0\\
        0 & 1 & 0\\
        0 & 0 & 1
    \end{bmatrix}
    , \quad \mathbf{I}_4 =
    \begin{bmatrix}
        1 & 0 & 0 & 0\\
        0 & 1 & 0 & 0\\
        0 & 0 & 1 & 0\\
        0 & 0 & 0 & 1
    \end{bmatrix}
$$
$$
\mathbf{I}_n =
    \begin{bmatrix}
        1       & 0         & 0         & \dots     & 0\\
        0       & 1         & 0         & \dots     & 0\\
        0       & 0         & 1         & \dots     & 0\\
        \vdots  & \vdots    & \vdots   & \ddots    & \vdots\\
        0       & 0         & 0         & \dots     & 1
    \end{bmatrix}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### To calculate the dimensions (or, *n*)
#### Essentially a square matrix with "1"s down the main diagonal
- To calculate the [dimensions](https://www.youtube.com/watch?v=l7p1X5pdDoc&list=PLGR_7q6BJHQFbTCW995GhRY1AwWuWOvBH&index=14),
we must remember how multiplication works.

#### If we know the end result, then we can work out the origins:
$$
    \begin{bmatrix}
         & \mathbf{I} &\\
        (? & \times & ?)
    \end{bmatrix} \cdot
    \begin{bmatrix}
         & \mathbf{B} &\\
        (2 & \times & 4)
    \end{bmatrix} = 
    \begin{bmatrix}
         & \mathbf{B} &\\
        (2 & \times & 4)
    \end{bmatrix}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Identify the dimensions of **I**
- We know that the dimensions of $\mathbf{B}$ must stay the same. We also know where to find the number of rows and columns of the final product.
- Recall that:
$$
    \begin{bmatrix}
         & \mathbf{A} &\\
        (m_A & \times & n_A)
    \end{bmatrix} \cdot
    \begin{bmatrix}
         & \mathbf{B} &\\
        (m_B & \times & n_B)
    \end{bmatrix} = 
    \begin{bmatrix}
         & \mathbf{AB} &\\
        (m_A & \times & n_B)
    \end{bmatrix}
$$
- Try to work it out, replacing A with I.

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Identify the dimensions of **I**
- From multiplication, the number of rows in $\mathbf{IB}$ must come from $\color{blue}{m_\mathbf{I}}$
- We also know they must be the same as in $\mathbf{B}$, so $\color{blue}{m_\mathbf{I}} = \color{blue}{m_\mathbf{IB}} = \color{red}{m_\mathbf{B}}$.
- From multiplication, we also know that $\mathbf{IB}$ is only defined if $\color{red}{n_\mathbf{I}}=\color{red}{m_\mathbf{B}}$
- Therefore, the number of columns in $\mathbf{I}$ must equal number of rows in $\mathbf{B}$
- So, $\color{red}{n_\mathbf{I}} = \color{blue}{m_\mathbf{B}}$
$$
\begin{bmatrix}
     & \mathbf{I} &\\
    (\color{blue}{a} & \times & \color{red}{a})
\end{bmatrix} \cdot
\begin{bmatrix}
     & \mathbf{B} &\\
    (\color{red}{a} & \times & b)
\end{bmatrix} = 
\begin{bmatrix}
     & \mathbf{IB} = \mathbf{B} &\\
    (\color{blue}{a} & \times & b)
\end{bmatrix}
$$


<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Identify the dimensions of **I**
- This means that the identity matrix has exactly the same number of rows as it has columns.
- The identity matrix is therefore always **a square matrix**.
- We denote a $2 \times 2$ identity matrix as $\mathbf{I}_2$
- In the general example above, The identity matrix is therefore $\mathbf{I}_a$
- We also know that the **order matters!!!!**


<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Identify the dimensions of **I**: Changing the order
#### Most Importantly, $\mathbf{I} \approx 1$
- Therefore, in terms of scalar multiplication 
$$
\mathbf{IB} = 1\cdot \mathbf{B}
$$
- Thus,
$$
\mathbf{IB} = \mathbf{BI} = 1\cdot \mathbf{B} = \mathbf{B}\cdot 1 = \mathbf{B}
$$

#### Thought Exercise
- Try to find the general rule for the identity matrix for $\mathbf{BI}$.
$$
\begin{bmatrix}
        & \mathbf{B}    &       \\
    (a  & \times        &   b)
\end{bmatrix}
\cdot
\begin{bmatrix}
        & \mathbf{I}    &       \\
    (?  & \times        &   ?)
\end{bmatrix} = 
\begin{bmatrix}
        & \mathbf{BI} = \mathbf{B}  &       \\
    (?  & \times                    &   ?)
\end{bmatrix}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Identify the dimensions of **I**: Changing the order
- From multiplication, the number of rows in $\mathbf{BI}$ must come from $m_\mathbf{B}$.
- To work out what $\mathbf{I}$'s dimensions are we can again get them from the final result. This time, $\color{blue}{n_\mathbf{BI}} = \color{blue}{n_\mathbf{I}}$, but to get $\mathbf{BI}=\mathbf{B}$, it must also be true that $\color{blue}{n_\mathbf{BI}} = \color{red}{n_\mathbf{B}}$, and therefore, $\color{blue}{n_\mathbf{I}} = \color{blue}{n_\mathbf{BI}} = \color{red}{n_\mathbf{B}}$.
- From multiplication, we know that $\mathbf{BI}$ is only defined if $\color{red}{n_\mathbf{B}}=\color{red}{m_\mathbf{I}}$.

### ... continued
- Therefore, the number of rows in $\mathbf{I}$ must equal number of columns in $\mathbf{B}$.
- So, $\color{red}{n_\mathbf{B}} = \color{red}{m_\mathbf{I}}$.
$$
\begin{bmatrix}
     & \mathbf{B} &\\
    (a & \times & \color{red}{b})
\end{bmatrix} \cdot
\begin{bmatrix}
     & \mathbf{I} &\\
    (\color{red}{b} & \times & \color{blue}{b})
\end{bmatrix} =
\begin{bmatrix}
     & \mathbf{BI} = \mathbf{B} &\\
    (a & \times & \color{blue}{b})
\end{bmatrix}
$$
- For the new ordering of the multiplication, the identity matrix is therefore $\mathbf{I}_b$.

#### What matters is that the result is the same!!
$$
\mathbf{IB} = \mathbf{BI} = \mathbf{B}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Exercises
1. Find the identity matrix for $\mathbf{IF}$, for
$$
\mathbf{F}=
  \begin{bmatrix}
    1 & 2 & 3 \\
    1 & 2 & 3 \\
    3 & 4 & 5
  \end{bmatrix}
$$
2. Find the identity matrix for $\mathbf{G}$, for $\mathbf{IG}$, where
$$
\mathbf{G}=
    \begin{bmatrix}
        266 & 2 & 9 & 65 & 1\\
        72 & 45 & 6n & 0 & 40\\
        \frac{3}{r} & 6 & 44 & 26 & 12\\
        11 & 3t & a & 4442 & \frac{n}{22}\\
        73 & 88 & 117 & 563 & 1
    \end{bmatrix}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Exercises continued...
3. Find the identity matrix for $\mathbf{AC}$, for $\mathbf{(AC)I}$, where
$$
\mathbf{A}=
    \begin{bmatrix}
        5 & 2 & 23\\
        3 & 4 & 3v\\
        c & 4 & 886
    \end{bmatrix}
, and \quad \mathbf{C} =
    \begin{bmatrix}
        \frac{3}{5} & 2 & e34 & 900\\
        3 & 4 & g & 23\\
        5 & \frac{1}{2} & i43 & 12
    \end{bmatrix}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New section %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New section %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

## The zero matrix
### Algebraic comparisons
- In standard algebra we can multiply a real number by zero, and the result is 0. So, $$a \cdot 0 = 0$$
- Again we can do something similar with matrices, called the [zero matrix](https://www.youtube.com/watch?v=LOf8bfjiLow&list=PLGR_7q6BJHQFbTCW995GhRY1AwWuWOvBH&index=15).
- The difference: this time we want a matrix the same size as we started out with, but with all values equal to zero.
- We denote the zero matrix as a bold zero, $\mathbf{0}$. So in matrix terms, matrix 
$$
\mathbf{A} \cdot  \mathbf{0} = \mathbf{0}
$$
- What dimensions do you expect the zero matrix to have?

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Usefulness and dimensions
- What is most important is understanding the operation. Where, 
$$
\mathbf{B} \cdot  \mathbf{0} = \mathbf{0}
$$
, and 
$$
\mathbf{0} \cdot  \mathbf{A} = \mathbf{0}
$$
, and 
$$
\mathbf{AB} \cdot  \mathbf{0} = \mathbf{0}
$$
- In terms of dimensions, we can just use a square matrix (like the identity matrix), but just make all elements equal to "0".

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Usefulness and dimensions
- But, the zero matrix used in multiplication does not need to be square. It only needs to satisfy the rules of matrix multiplication. 
$$
n_A = m_B
$$
- The dimensions of the resulting zero matrix will then depend on original matrix and the size chosen for the zero matrix.


<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New section %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New section %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

## Leontief Models

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Expanding the simple model to a large general model:

Lets say we want to find the total units of good $i$ needed for
one unit of good $j$ = $a_{ij}$, where $a_{i}$ is some proportion.

If we let the number of units of good $j = x_{j}$, and we consider that
each $x$ can be a different good that requires some level of production
of good $i$, then for $n$ different products.

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### For $j$ units of good $i$ across $n$ products

#### We are interested in good $i$
- The first row will be related to producing product $j$ using $i$:
$$
\begin{matrix}
    a_{ij}x_j + & a_{ij}x_j & + &  \dots & + & a_{in}x_n
\end{matrix}
$$

If industry $i$ must supply some total level of demand $x_i$, and
additional demand for good $i = b_i$, then
$$
\begin{matrix}
    x_i = a_{ij}x_j + & a_{ij}x_j & + &  \dots & + & a_{in}x_n + b_i
\end{matrix}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Expanding the number of industries

If we expand the number of industries to $m$ total indistries then we
get:

$$
\begin{matrix}
    x_1     & = & a_{11}x_1     +   & a_{12}x_2     & + &  \dots  & + &  a_{1n}x_n & + & b_1    \\
    x_2     & = & a_{2j}x_j     +   & a_{2j}x_j     & + &  \dots  & + &  a_{2n}x_n & + & b_2    \\
    \vdots  &   & \vdots            & \vdots        &   &  \ddots &   &  \vdots    &   & \vdots \\
    x_n     & = & a_{n1}x_1     +   & a_{n2}x_2     & + &  \dots  & + &  a_{nn}x_n & + & b_n
\end{matrix}
$$

Rearranging all terms with $x$ to the left, and leaving only the
additional demand component

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Rearranging all $x$ terms to the left

Rearranging all terms with an $x$ to the left, and leaving only the
additional demand component to the right.

- This results in the following:

$$
\begin{matrix}
    (1-a_{11})x_1   & - & a_{12}x_2     & - &  \dots & - & a_{1n}x_n     & = & b_1\\
    -a_{2j}x_1      & + & (1-a_{2j})x_2 & - &  \dots & - & a_{2n}x_n     & = & b_2\\
    \vdots          & - & \vdots        & + &  \dots & - & \vdots        & = & \vdots \\
    -a_{n1}x_1      & - & a_{n2}x_2     & - &  \dots & + & (1-a_{nn})x_n & = & b_n
  \end{matrix}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### Separating the $x$ variables from the coefficients

- We can arrange the coeficients like this, with the $x$ variables as a vector.

$$
    \begin{bmatrix}
        (1-a_{11})   & - &  a_{12}          & - &  \dots & - & a_{1n}     \\
        -a_{2j}      & + &  (1-a_{2j})      & - &  \dots & - & a_{2n}     \\
        \vdots       & - &  \vdots          & + &  \dots & - & \vdots   \\
        -a_{n1}      & - &  a_{n2}          & - &  \dots & + & (1-a_{nn})
    \end{bmatrix}
\cdot
    \begin{bmatrix}
      x_1\\
      x_2\\
      \vdots \\
      x_n
    \end{bmatrix}
=
    \begin{bmatrix}
      b_1\\
      b_2\\
      \vdots \\
      b_n
    \end{bmatrix}
$$

- In the box on the left you can see, going down the main diagonal is the number $1$.
- except for this, it looks like the whole coefficient matrix ($\mathbf{A}$) is negative.
- As we know, another square matrix, with the number $1$ all the way down the diagonal is the identity matrix, $\mathbf{I}$!

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### In matrix form:
This would look something like:

$$
    \begin{bmatrix}
        1       & 0         & \dots     & 0\\
        0       & 1         & \dots     & 0\\
        \vdots  & \vdots    & \ddots    & \vdots\\
        0       & 0         & \dots     & 1
    \end{bmatrix}
-
    \begin{bmatrix}
        a_{11}      & + &  a_{12}   & + &  \dots & + & a_{1n}     \\
        a_{2j}      & + &  a_{2j}   & + &  \dots & + & a_{2n}     \\
        \vdots      & + &  \vdots   & + &  \dots & + & \vdots   \\
        a_{n1}      & + &  a_{n2}   & + &  \dots & + & a_{nn}
    \end{bmatrix}
$$

#### In mathematical notation this can be writen as

$$
\mathbf{I}-\mathbf{A}
$$

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

### The full expression in mathematical notation

#### We get:

$$
(\mathbf{I} - \mathbf{A}) \cdot \mathbf{x} = \mathbf{b}
$$

#### The solutions vector of $x$ would then be:

$$
(\mathbf{I} - \mathbf{A})^{-1} \cdot (\mathbf{I} - \mathbf{A}) \cdot \mathbf{x}^* = (\mathbf{I} - \mathbf{A})^{-1} \cdot \mathbf{b}
$$

$$
1 \cdot \mathbf{x}^* = (\mathbf{I} - \mathbf{A})^{-1} \cdot \mathbf{b}
$$
Or just
$$
\mathbf{x}^* = (\mathbf{I} - \mathbf{A})^{-1} \cdot \mathbf{b}
$$

- Note the order of multiplication on the right hand side (RHS)


<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New section %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New section %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%%%%%% New slide %%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->

## Exercises

12.?
12.??
12.??


